{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../original_images/01.jpg\"},\n",
    "    \"sterile_test\": {\"filename\": \"../original_images/02.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../original_images/05.png\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(images))\n",
    "fig.set_size_inches(6, 2.5*len(images))\n",
    "for index, image in enumerate([\"reference\", \"sterile_test\", \"real_world\"]):\n",
    "    axes[index].imshow(images[image][\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# detectors are for finding keypoints.  They often also support computing\n",
    "detectors = {\"fast\": cv2.FastFeatureDetector_create(), # lots of points (2159) all over\n",
    "             \"brisk\": cv2.BRISK_create(),              \n",
    "             \"akaze\": cv2.AKAZE_create(),  # strange delocalization\n",
    "             \"kaze\": cv2.KAZE_create(),  # strange delocalization\n",
    "             \"agast\": cv2.AgastFeatureDetector_create(),\n",
    "             \"gftt\": cv2.GFTTDetector_create(),\n",
    "             \"mser\": cv2.MSER_create(),  # very few keypoints (80)\n",
    "             \"orb\": cv2.ORB_create(),\n",
    "             \"star\": cv2.xfeatures2d.StarDetector_create(),\n",
    "             \"sift\": cv2.xfeatures2d.SIFT_create(),\n",
    "             \"surf\": cv2.xfeatures2d.SURF_create(),\n",
    "            }\n",
    "descriptors_only = {\n",
    "    \"freak\": cv2.xfeatures2d.FREAK_create(),\n",
    "    \"latch\": cv2.xfeatures2d.LATCH_create(),\n",
    "    \"lucid\": cv2.xfeatures2d.LUCID_create(1, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = images[\"reference\"][\"image\"]\n",
    "for algorithm in detectors:\n",
    "    plt.figure()\n",
    "    kps = detectors[algorithm].detect(image)\n",
    "    plt.imshow(cv2.drawKeypoints(image, kps, (255, 0,0)))\n",
    "    plt.title(algorithm + \" (%d pts)\"%len(kps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compute features\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_features(image, detector_alg, descriptor_alg=None):\n",
    "    data = image[\"image\"]\n",
    "    if descriptor_alg in detectors:\n",
    "        kps, descriptors = detectors[descriptor_alg].detectAndCompute(data, None)\n",
    "    elif descriptor_alg in descriptors_only:\n",
    "        kps = detectors[detector_alg].detect(data)\n",
    "        kps, descriptors = descriptors_only[descriptor_alg].compute(data, kps)\n",
    "    else:\n",
    "        raise ValueError(\"unknown algorithm passed to descriptor stage\")\n",
    "    image[\"kps\"] = kps\n",
    "    image[\"descriptors\"] = descriptors\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match keypoint descriptors\n",
    "=========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perspective_match(reference, unknown, use_flann=False, min_match_count=10):\n",
    "    if use_flann:\n",
    "        FLANN_INDEX_KDTREE = 0\n",
    "        FLANN_INDEX_LSH    = 6\n",
    "        # floating point algorithms\n",
    "        if descriptor in [\"sift\", \"surf\"]:\n",
    "            index_params = dict(algorithm = FLANN_INDEX_KDTREE,\n",
    "                                trees = 5)\n",
    "        # binary algorithms\n",
    "        else:\n",
    "            index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                                table_number = 6, # 12\n",
    "                                key_size = 12,     # 20\n",
    "                                multi_probe_level = 1) #2\n",
    "        search_params = dict(checks = 50)\n",
    "        matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    else:\n",
    "        matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(reference[\"descriptors\"],\n",
    "                               unknown[\"descriptors\"],\n",
    "                               k=2)\n",
    "    good = []\n",
    "    matchesMask=None\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "    if len(good)>min_match_count:\n",
    "        src_pts = np.float32([ reference[\"kps\"][m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ unknown[\"kps\"][m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "        # this limits matches to being within the identified subimage\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "\n",
    "    else:\n",
    "        print \"Not enough matches are found (%d/%d)\" % (len(good), min_match_count)\n",
    "        matchesMask, good = None, None\n",
    "    return matchesMask, good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_matches(reference_features, unknown_features, mask, good_pts):\n",
    "    fig = plt.figure()\n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                       singlePointColor = (255,0,0),\n",
    "                       matchesMask = mask,\n",
    "                       flags = 2)\n",
    "\n",
    "    img3 = cv2.drawMatches(reference_features[\"image\"],\n",
    "                           reference_features[\"kps\"],\n",
    "                           unknown_features[\"image\"],\n",
    "                           unknown_features[\"kps\"],\n",
    "                           good_pts,None,**draw_params)\n",
    "    plt.imshow(img3)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrapper(reference, unknown, detector_alg, \n",
    "            descriptor_alg=None, use_flann=False,\n",
    "            min_match_count=5):\n",
    "    if not descriptor_alg:\n",
    "        descriptor_alg = detector_alg\n",
    "    reference_features = compute_features(reference, \n",
    "                                          detector_alg, \n",
    "                                          descriptor_alg)\n",
    "    unknown_features = compute_features(unknown, \n",
    "                                        detector_alg, \n",
    "                                        descriptor_alg)\n",
    "    matchesMask, good_pts = perspective_match(reference_features,\n",
    "                                              unknown_features,\n",
    "                                             use_flann=use_flann,\n",
    "                                             min_match_count=min_match_count)\n",
    "    fig = draw_matches(reference_features, unknown_features, \n",
    "                 matchesMask, good_pts)\n",
    "    fig.gca().set_title(\"keypoints: {}, detector: {}, Matcher: {}\".format(\n",
    "        detector_alg, descriptor_alg, \n",
    "        \"FLANN\" if use_flann else \"Brute Force\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrapper(images[\"reference\"], images[\"sterile_test\"], \"kaze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrapper(images[\"reference\"], images[\"real_world\"], \"kaze\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
