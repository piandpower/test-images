{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "#%matplotlib inline\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using original non-atf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../original_images/01.jpg\"},\n",
    "    \"sterile_test\": {\"filename\": \"../original_images/02.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../original_images/05.png\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using new atf parts and whole images (matches to parts but not whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../atf_images/parts/3_butt.jpg\"},\n",
    "    \"sterile_test\": {\"filename\": \"../atf_images/parts/6_butt.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../atf_images/images/6.jpg\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using other parts/whole atf images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../atf_images/parts/3_clip.jpg\"},\n",
    "    \"sterile_test\": {\"filename\": \"../atf_images/parts/5_clip.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../atf_images/images/5.jpg\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pistol_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../kris_images/Pistol_22/IMG_6082.jpg\"},\n",
    "    \"sterile_test\": {\"filename\": \"../kris_images/Pistol_22/IMG_6107.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../kris_images/Pistol_22/IMG_6079.jpg\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winchester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../kris_images/Winchester/IMG_6123.jpg\"},\n",
    "    \"sterile_test\": {\"filename\": \"../kris_images/Winchester/IMG_6123.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../kris_images/Winchester/IMG_6122.jpg\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winchester Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../kris_images/Winchester_small/IMG_6121.JPG_resizeXpct.jpg\"},\n",
    "    \"sterile_test\": {\"filename\": \"../kris_images/Winchester_small/IMG_6123.JPG_resizeXpct.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../kris_images/Winchester_small/IMG_6122.JPG_resizeXpct.jpg\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dragoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../kris_images/Dragoon/IMG_6169.jpg\"},\n",
    "    \"sterile_test\": {\"filename\": \"../kris_images/Dragoon/IMG_6169.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../kris_images/Dragoon/IMG_6188.jpg\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = {\n",
    "    \"reference\": {\"filename\":\"../kris_images/Pistol_22/IMG_6079_bgremoved.JPG\"},\n",
    "    \"sterile_test\": {\"filename\": \"../kris_images/Pistol_22/IMG_6107.jpg\"},\n",
    "    \"real_world\": {\"filename\": \"../kris_images/Pistol_22/IMG_6082.jpg\"}\n",
    "                    }\n",
    "for image in images:\n",
    "    images[image][\"image\"] = cv2.imread(images[image][\"filename\"])\n",
    "    images[image][\"image\"] = cv2.cvtColor(images[image][\"image\"], cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(images))\n",
    "fig.set_size_inches(6, 2.5*len(images))\n",
    "for index, image in enumerate([\"reference\", \"sterile_test\", \"real_world\"]):\n",
    "    axes[index].imshow(images[image][\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# detectors are for finding keypoints.  They often also support computing\n",
    "detectors = {\"fast\": cv2.FastFeatureDetector_create(), # lots of points (2159) all over\n",
    "             \"brisk\": cv2.BRISK_create(),              \n",
    "             \"akaze\": cv2.AKAZE_create(),  # strange delocalization\n",
    "             \"kaze\": cv2.KAZE_create(),  # strange delocalization\n",
    "             \"agast\": cv2.AgastFeatureDetector_create(),\n",
    "             \"gftt\": cv2.GFTTDetector_create(),\n",
    "             \"mser\": cv2.MSER_create(),  # very few keypoints (80)\n",
    "             \"orb\": cv2.ORB_create(),\n",
    "             \"star\": cv2.xfeatures2d.StarDetector_create(),\n",
    "             \"sift\": cv2.xfeatures2d.SIFT_create(),\n",
    "             \"surf\": cv2.xfeatures2d.SURF_create(),\n",
    "            }\n",
    "descriptors_only = {\n",
    "    \"freak\": cv2.xfeatures2d.FREAK_create(),\n",
    "    \"latch\": cv2.xfeatures2d.LATCH_create(),\n",
    "    \"lucid\": cv2.xfeatures2d.LUCID_create(1, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = images[\"reference\"][\"image\"]\n",
    "for algorithm in detectors:\n",
    "    plt.figure()\n",
    "    kps = detectors[algorithm].detect(image)\n",
    "    plt.imshow(cv2.drawKeypoints(image, kps, (255, 0,0)))\n",
    "    plt.title(algorithm + \" (%d pts)\"%len(kps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Compute features\n",
    "================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_features(image, detector_alg, descriptor_alg=None):\n",
    "    data = image[\"image\"]\n",
    "    if descriptor_alg in detectors:\n",
    "        kps, descriptors = detectors[descriptor_alg].detectAndCompute(data, None)\n",
    "    elif descriptor_alg in descriptors_only:\n",
    "        kps = detectors[detector_alg].detect(data)\n",
    "        kps, descriptors = descriptors_only[descriptor_alg].compute(data, kps)\n",
    "    else:\n",
    "        raise ValueError(\"unknown algorithm passed to descriptor stage\")\n",
    "    image[\"kps\"] = kps\n",
    "    image[\"descriptors\"] = descriptors\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match keypoint descriptors\n",
    "=========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perspective_match(reference, unknown, use_flann=False, min_match_count=10,descriptor=None):\n",
    "    if use_flann:\n",
    "        FLANN_INDEX_KDTREE = 0\n",
    "        FLANN_INDEX_LSH    = 6\n",
    "        # floating point algorithms\n",
    "        if descriptor in [\"sift\", \"surf\"]:\n",
    "            index_params = dict(algorithm = FLANN_INDEX_KDTREE,\n",
    "                                trees = 5)\n",
    "        # binary algorithms\n",
    "        else:\n",
    "            index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                                table_number = 6, # 12\n",
    "                                key_size = 12,     # 20\n",
    "                                multi_probe_level = 1) #2\n",
    "        search_params = dict(checks = 50)\n",
    "        matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    else:\n",
    "        matcher = cv2.BFMatcher()\n",
    "    matches = matcher.knnMatch(reference[\"descriptors\"],\n",
    "                               unknown[\"descriptors\"],\n",
    "                               k=2)\n",
    "    good = []\n",
    "    matchesMask=None\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "    if len(good)>min_match_count:\n",
    "        src_pts = np.float32([ reference[\"kps\"][m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ unknown[\"kps\"][m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "        # this limits matches to being within the identified subimage\n",
    "        try:\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "        except AttributeError:\n",
    "            matchesMask, good = None, None\n",
    "\n",
    "    else:\n",
    "        print \"Not enough matches are found (%d/%d)\" % (len(good), min_match_count)\n",
    "        matchesMask, good = None, None\n",
    "    return matchesMask, good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_matches(reference_features, unknown_features, mask, good_pts):\n",
    "    fig = plt.figure()\n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                       singlePointColor = (255,0,0),\n",
    "                       matchesMask = mask,\n",
    "                       flags = 2)\n",
    "\n",
    "    img3 = cv2.drawMatches(reference_features[\"image\"],\n",
    "                           reference_features[\"kps\"],\n",
    "                           unknown_features[\"image\"],\n",
    "                           unknown_features[\"kps\"],\n",
    "                           good_pts,None,**draw_params)\n",
    "    plt.imshow(img3)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrapper(reference, unknown, detector_alg, \n",
    "            descriptor_alg=None, use_flann=False,\n",
    "            min_match_count=5):\n",
    "    if not descriptor_alg:\n",
    "        descriptor_alg = detector_alg\n",
    "    reference_features = compute_features(reference, \n",
    "                                          detector_alg, \n",
    "                                          descriptor_alg)\n",
    "    unknown_features = compute_features(unknown, \n",
    "                                        detector_alg, \n",
    "                                        descriptor_alg)\n",
    "    print('ref features: ',len(reference_features['kps']))\n",
    "    print('unknown features: ',len(unknown_features['kps']))\n",
    "    matchesMask, good_pts = perspective_match(reference_features,\n",
    "                                              unknown_features,\n",
    "                                             use_flann=use_flann,\n",
    "                                             min_match_count=min_match_count,\n",
    "                                             descriptor=descriptor_alg)\n",
    "    fig = draw_matches(reference_features, unknown_features, \n",
    "                 matchesMask, good_pts)\n",
    "    fig.gca().set_title(\"keypoints: {}, detector: {}, Matcher: {}\".format(\n",
    "        detector_alg, descriptor_alg, \n",
    "        \"FLANN\" if use_flann else \"Brute Force\"))\n",
    "    if good_pts is not None:\n",
    "        return len(good_pts)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findAllCombs(a_list,b_list,ab_list):\n",
    "    combs = []\n",
    "    for a in a_list:\n",
    "        for b in b_list:\n",
    "            combs.append((a,b))\n",
    "        for ab in ab_list:\n",
    "            combs.append((a,ab))\n",
    "    for b in b_list:\n",
    "        for ab in ab_list:\n",
    "            combs.append((ab,b))\n",
    "    for ab in ab_list:\n",
    "        combs.append((ab,ab))\n",
    "    return combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_list = ['brisk','akaze','kaze','orb']#,'sift','surf']\n",
    "det_list = ['fast','agast','gftt','mser','star']\n",
    "desc_list = ['freak','latch','lucid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(findAllCombs(det_list,desc_list,both_list),\n",
    "                  columns=['detector','descriptor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['combo'] = df['detector']+df['descriptor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.set_index('combo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in df.index:\n",
    "    print(row)\n",
    "    print(df.loc[row,'detector'])\n",
    "    print(df.loc[row,'descriptor'])\n",
    "    df.loc[row,'num_matches'] = wrapper(images[\"reference\"], \n",
    "                                        images[\"real_world\"], \n",
    "                                        detector_alg=df.loc[row,'detector'], \n",
    "                                        descriptor_alg=df.loc[row,'descriptor'])#,\n",
    "                                        #use_flann=True)\n",
    "    print(df.loc[row,'num_matches'])\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.sort_values('num_matches', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_values('num_matches', ascending=False).to_csv(\"../performance_ranking_Winchester_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, comb in enumerate(findAllCombs(det_list,desc_list,both_list)):\n",
    "#for i, comb in enumerate(test):\n",
    "    if i < 8:\n",
    "        print('-'*20)\n",
    "        print('combo: '+str(i))\n",
    "        print(comb)\n",
    "        try:\n",
    "            wrapper(images[\"reference\"], images[\"real_world\"], detector_alg=comb[0], descriptor_alg=comb[1])\n",
    "        except AttributeError:\n",
    "            print('Homography not found')\n",
    "        except:\n",
    "            print('there was an error')\n",
    "        print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wrapper(images[\"reference\"], images[\"real_world\"], \"agast\", descriptor_alg='latch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homography Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global coords1\n",
    "coords1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "plt.title(\"Select 4 Points\")\n",
    "\n",
    "implot = ax.imshow(images[\"reference\"]['image'])\n",
    "\n",
    "def onclick(event):\n",
    "    #global coords\n",
    "    #coords = []\n",
    "    if event.xdata != None and event.ydata != None:\n",
    "        print(event.xdata, event.ydata)\n",
    "        coords1.append((event.xdata, event.ydata))\n",
    "    \n",
    "        \n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print coords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global coords2\n",
    "coords2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "fig = plt.gcf()\n",
    "plt.title(\"Select 4 Points\")\n",
    "\n",
    "implot = ax.imshow(images[\"real_world\"]['image'])\n",
    "\n",
    "def onclick(event):\n",
    "    #global coords\n",
    "    #coords = []\n",
    "    if event.xdata != None and event.ydata != None:\n",
    "        print(event.xdata, event.ydata)\n",
    "        coords2.append((event.xdata, event.ydata))\n",
    "    \n",
    "        \n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print coords2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h, status = cv2.findHomography(np.array(coords1),np.array(coords2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[\"reference\"]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[\"real_world\"]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_trans = cv2.warpPerspective(images[\"real_world\"]['image'],h,\n",
    "                                (images[\"reference\"]['image'].shape[1],\n",
    "                                 images[\"reference\"]['image'].shape[0]))\n",
    "plt.imshow(img_trans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
